\documentclass{hw}

\title{6.437 Project, Part 1}
\author{Phil Chodrow}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}

\newtheorem{thm}{Theorem}
\newtheorem{lm}{Lemma}
\newtheorem{cor}{Corrolary}
\newtheorem{clm}{Claim}

\newtheorem*{thm*}{Theorem}
\newtheorem*{lm*}{Lemma}
\newtheorem*{cor*}{Corrolary}
\newtheorem*{clm*}{Claim}

\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand\decision[2]{\underset{#2}{\overset{#1}{\gtreqless}}}
\newcommand{\argmax}{\operatornamewithlimits{argmax}}
\newcommand{\argmin}{\operatornamewithlimits{argmin}}
\newcommand\abs[1]{\left|#1\right|}
\newcommand\prob[0]{\mathbb{P}}
\newcommand\E[0]{\mathbb{E}}
\newcommand\R[0]{\mathbb{R}}

\makeatletter
\def\BState{\State\hskip-\ALG@thistlm}
\makeatother

\begin{document}
%-----------------------------------------------
\problem{}
	We consider the following cdeciphering problem. Let $\mathbf{X}$ be a random variable representing the plaintext corresponding to an observed ciphertext $\mathbf{Y}$, where $\mathbf{Y} = f(\mathbf{X})$ and $f:\mathcal{A} \rightarrow \mathcal{A}$ is a permutation of the English alphabet $\mathcal{A}$, which includes lowercase letters, spaces, and periods. 

	We assume that the sequence of characters in English text can be approximated as a stationary Markov chain, where the probability of a symbol depends only on the symbol that precedes it. Formally, if we number the symbols of $\mathcal{A}$ from $1$ to $m \abs{\mathcal{A}}$, then 
	\begin{equation}
		\prob(X_k = i\;|\; X_{k-1} = j) = M_{ij}\;,
	\end{equation}
	where $\mathbf{M}$ is the transition matrix. Furthermore, let the marginal probability of each symbol be given by 
	\begin{equation}
		P_i \triangleq \prob(X_k = i), \quad i = 1, 2, \ldots, m\;,
	\end{equation}
	and let $\mathbf{P} = [P_i]$ be the vector of marginal probabilities. 

\solution
	\part
		Since $f$ is bijective by hypothesis, we can write
		\begin{align}
			p_{\mathbf{Y}|F}(\mathbf{y}|f) &= \prob(\mathbf{Y} = \mathbf{y} \;|\; F = f) \\
			&= \prob(F(\mathbf{X}) = \mathbf{y} \;|\; F = f) \\
			&= \prob(\mathbf{X} = f^{-1}(\mathbf{y})) \\
			&= (p_\mathbf{X} \circ f^{-1})(\mathbf{y})\;.
		\end{align}
	\part
		Let $\mathcal{C}$ be the space of permutations of $\mathcal{A}$. Then, $\abs{\mathcal{C}} = \abs{\mathcal{A}}!$, so that $p_F(f) = \frac{1}{\abs{\mathcal{A}}!}$ for all $f$, and we can write 
		\begin{align}
			p_{F|\mathbf{Y}}(f|\mathbf{y}) &= \frac{p_{\mathbf{Y}|F}(\mathbf{y}|f)p_F(f)}{p_\mathbf{Y}(\mathbf{y})} \\
			&= \frac{1}{\abs{\mathcal{A}}!} \frac{(p_\mathbf{X} \circ f^{-1})(\mathbf{y})}{\sum_{f \in \mathcal{C}}(p_\mathbf{X} \circ f^{-1})(\mathbf{y})}\;. \label{one}
		\end{align}
		We can further express the likelihood $(p_\mathbf{X} \circ f^{-1})(\mathbf{y})$ as follows. Let $\mathbf{x} = f^{-1}(\mathbf{y})$; then, 
		\begin{align}
			 (p_\mathbf{X} \circ f^{-1})(\mathbf{y}) &= p_{\mathbf{X}}(\mathbf{x}) \\
			 &= P(x_1) \prod_{k = 2}^K \prob(X_{k} = x_k\;|\;X_{k-1} x_{k-1}) \\
			 &= P(x_1) \prod_{k = 2}^K M_{x_k,x_{k-1}} \label{two}
		\end{align}
	\part
		The normalization $p_\mathbf{Y}(\mathbf{y}) = \sum_{f \in \mathcal{C}}(p_\mathbf{X} \circ f^{-1})(\mathbf{y})$ is impractical to calculate, since it involves the evaluation and summation of $\abs{A}! = 28! \approx 10^{29}$ terms. 
%-----------------------------------------------
\problem{}
	We develop some of the necessary structure to apply Markov-Chain Monte Carlo to the ciphering problem. 
\solution
	\part
		There are $\frac{\abs{\mathcal{A}}(\abs{\mathcal{A}} - 1)}{2}$ unordered pairs of symbols from the alphabet. To a fixed $f$ and pair of symbols, there exists exactly one $f'$ that agrees with $f$ on all but those two symbols, out of a total of $\abs{\mathcal{A}}$ possible ciphers. So, the probability that a uniformly-selected $f'$ matches $f$ on a specified pair of symbols is $\frac{1}{\abs{\mathcal{A}}!}$, and the probability that $f'$ matches $f$ on some pair is 
		\begin{equation}
			\frac{\abs{\mathcal{A}}(\abs{\mathcal{A}} - 1) / 2}{\abs{\mathcal{A}}!} = \frac{1}{2 (\abs{\mathcal{A}} - 2)!}\;.
		\end{equation}
		What's nice about this result is that, if we construct a proposal Markov chain where ciphers have links between them iff they differ on exactly two symbols, then the neighborhood of a given cipher will be relatively sparse. 
	\part
		We can construct a Markov chain whose stationary distribution is the posterior of Problem 1(b) as follows. Let $n(f)$ be the set of ciphers that differ from $f$ in exactly two symbols. Let $V$ our proposed chain be given by the transition probabilities 
		\begin{equation}
			\prob(V_t = f'\;|\; V_{t-1} = f) = \begin{cases}\frac{1}{2(\abs{\mathcal{A}} - 2)} & f' \in n(f)\\
			0 & \text{otherwise}\end{cases}
		\end{equation}
		For the remainder of this problem, we'll assume that $f' \in n(f)$. We can then compute the acceptance factor as 
		\begin{align} 
			a(f \rightarrow f') &= \min \left\{1, \frac{p_{\mathbf{Y}|F}(\mathbf{y}|f')p_F(f')V(f'|f)}{p_{\mathbf{Y}|F}(\mathbf{y}|f)p_F(f)V(f|f')}  \right\} \\
			&= \min \left\{1, \frac{p_{\mathbf{Y}|F}(\mathbf{y}|f')}{p_{\mathbf{Y}|F}(\mathbf{y}|f)}  \right\}\;,
		\end{align}
		where we have used the fact that the prior $p_F$ and the proposed transition probabilities are uniform. So, the acceptance factor is just a likelihood ratio. So, the modified Markov chain $W$ has transition probabilities for $f' \neq f$ given by 
		\begin{equation}
			\prob(W_t = f' \;|\; W_{t - 1} = f) = 
				V(f'|f) a(f' \rightarrow f) = \frac{1}{2 (\abs{\mathcal{A}} - 2)!} \min \left\{1, \frac{p_{\mathbf{Y}|F}(\mathbf{y}|f')}{p_{\mathbf{Y}|F}(\mathbf{y}|f)}  \right\} \;,
		\end{equation}
		and 
		\begin{equation}
			\prob(W_t = f \;|\; W_{t - 1} = f) = 1 - \sum_{f' \in n(f), f' \neq f} \prob(W_t = f' \;|\; W_{t - 1} = f)\;.
		\end{equation}
	\part
		An explicit algorithm is: 
		\begin{algorithm}
		\caption{Metropolis-Hastings Algorithm for Decoding Ciphertext}\label{euclid}
		\begin{algorithmic}[1]
		\Procedure{findCipher}{$mixTime$, $nSamples$}
			\State $f_0 \gets U[\mathcal{C}]$ \Comment{Initial state, uniform random}
			\State $i \gets 1$ 
			\State $n \gets 1$
			\State $S \gets \{\}$ \Comment{Empty dictionary of samples}
		\While {$n \leq nSamples$} 
			\State $\tilde{f}_i \gets U[ne(f_{i-1})] $ \Comment{Uniform random neighbor of $f_{i-1}$}
			\State $a_i \gets \min \left\{1, \frac{p_{\mathbf{Y}|F}(\mathbf{y}|\tilde{f}_i)}{p_{\mathbf{Y}|F}(\mathbf{y}|f_{i-1})}\right\}$ \Comment{Acceptance probability, using \eqref{one} and \eqref{two}}
			\State $u \gets ~ U[0,1]$
			\If {$u \geq a_i$}
				\State $f_i \gets \tilde{f}_i$
				\State $i \gets i + 1$
			\EndIf
			\If {$i \geq mixTime$} \Comment{If chain is mixed}
				\State $S[f_i] \gets S[f_i] + 1$ \Comment{Add sample to dict}
				\State $n \gets n+1$
			\EndIf
		\EndWhile
		\Return $\argmax S$ \Comment{Return the empirical mode of the samples}

		\EndProcedure
		\end{algorithmic}
		\end{algorithm}

		

%-----------------------------------------------
\problem{}
	
\solution


\end{document}